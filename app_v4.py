import streamlit as st
import pandas as pd
import numpy as np
import joblib
import json
import plotly.graph_objects as go
from datetime import datetime, timedelta
import requests
import warnings
warnings.filterwarnings('ignore')

# ----------------------------
# Page configuration
st.set_page_config(
    page_title="Mumbai Street Vendor Demand Forecasting",
    page_icon="üçõ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ----------------------------
# Load model and artifacts
@st.cache_resource
def load_model_artifacts():
    try:
        try:
            model = joblib.load('xgb_model.pkl')
            model_type = "XGBoost"
        except:
            model = joblib.load('rf_model.pkl')
            model_type = "Random Forest"
        
        label_encoders = joblib.load('label_encoders.pkl')
        feature_columns = joblib.load('feature_columns.pkl')

        with open('model_metadata.json', 'r') as f:
            metadata = json.load(f)

        return model, label_encoders, feature_columns, metadata, model_type
    except Exception as e:
        st.error(f"Error loading model: {e}")
        return None, None, None, None, None

model, label_encoders, feature_columns, metadata, model_type = load_model_artifacts()
if model is None:
    st.stop()

# ----------------------------
# Load historical data
@st.cache_data
def load_historical_data():
    try:
        df = pd.read_csv('mumbai_vendors_hourly_20250701_20250930.csv')
        df['datetime_parsed'] = pd.to_datetime(df['datetime'], errors='coerce')
        if df['datetime_parsed'].dt.tz is None:
            df['datetime_parsed'] = df['datetime_parsed'].dt.tz_localize('Asia/Kolkata')
        else:
            df['datetime_parsed'] = df['datetime_parsed'].dt.tz_convert('Asia/Kolkata')
        return df
    except Exception as e:
        st.error(f"Error loading historical data: {e}")
        return None

historical_data = load_historical_data()

# ----------------------------
# Weather Alerts using WeatherAPI
@st.cache_data(ttl=600)
def get_weather_alerts():
    API_KEY = "e9323a9f57e6466e91d180135211911"
    location = "Mumbai"
    url = f"http://api.weatherapi.com/v1/alerts.json?key={API_KEY}&q={location}"
    try:
        response = requests.get(url)
        data = response.json()
        if "alerts" in data and data["alerts"]["alert"]:
            alerts = data["alerts"]["alert"]
            alert_list = []
            for a in alerts:
                alert_list.append({
                    "headline": a.get("headline", "No title"),
                    "severity": a.get("severity", "Unknown"),
                    "event": a.get("event", "N/A"),
                    "effective": a.get("effective", "N/A"),
                    "expires": a.get("expires", "N/A"),
                    "desc": a.get("desc", "No details available.")
                })
            return alert_list
        else:
            return []
    except Exception as e:
        st.warning(f"Error fetching weather alerts: {e}")
        return []

# ----------------------------
# Fetch current weather for Mumbai using WeatherAPI
@st.cache_data(ttl=600)
def get_current_weather():
    API_KEY = "e9323a9f57e6466e91d180135211911"
    location = "Mumbai"
    url = f"http://api.weatherapi.com/v1/current.json?key={API_KEY}&q={location}&aqi=no"
    try:
        response = requests.get(url)
        data = response.json()
        if data:
            location_str=f"{data['location']['name']} {data['location']['region']} {data['location']['country']}"
            last_updated = data['current']["last_updated"]
            temperature=data['current']["temp_c"]
            humidity=data['current']["humidity"]
            rainfall= data['current']["precip_mm"]
            condition=  data['current']["condition"]["text"]
            return temperature, humidity, rainfall , condition,last_updated,location_str
        else:
            st.warning("Failed to fetch weather, using default values.")
            return 28.0, 80.0, 0.0, "Clear", datetime.now().strftime("%Y-%m-%d %H:%M:%S"), "Mumbai"
    except:
        st.warning("Error fetching weather, using default values.")
        return 28.0, 80.0, 0.0, "Clear", datetime.now().strftime("%Y-%m-%d %H:%M:%S"), "Mumbai"

st.toast("Current Weather Data Extracted!", icon="üéâ")  
temperature, humidity, rainfall , condition,last_updated,location = get_current_weather()
current_date = datetime.now().date()
current_hour = datetime.now().hour

# ----------------------------
# App header
st.markdown("<h1 style='text-align:center'>üçõ Mumbai Street Vendor Demand Forecasting</h1>", unsafe_allow_html=True)
st.markdown("<p style='text-align:center'>Predict hourly demand and explore scenario simulations with interactive charts.</p>", unsafe_allow_html=True)

# ----------------------------
# Sidebar controls
st.sidebar.header("üìä Prediction Controls")

vendor_options = {
    'vendor_01': 'BKC_Pavbhaji (Business District)',
    'vendor_02': 'Churchgate_Chai (Near College)', 
    'vendor_03': 'Dadar_Chaat (Market)',
    'vendor_04': 'Andheri_Juice (Metro Station)',
    'vendor_05': 'Powai_Dessert (Office Area)'
}

selected_vendor = st.sidebar.selectbox(
    "Select Vendor:",
    options=list(vendor_options.keys()),
    format_func=lambda x: vendor_options[x]
)

st.sidebar.subheader("üìÖ Date & Time")
selected_date = st.sidebar.date_input("Select Date:", value=current_date)
selected_hour = st.sidebar.slider("Select Hour:", 0, 23, current_hour)

st.sidebar.subheader("üå§Ô∏è Weather Conditions (Auto-Filled)")
st.sidebar.text(f"‚òÅÔ∏è Condition: {condition} ")
st.sidebar.text(f"üìç Location: {location} ")
st.sidebar.text(f"üïí Last Updated: {last_updated}")
st.sidebar.text(f"üå°Ô∏è Temperature: { temperature:.1f} ¬∞C" )
st.sidebar.text(f"üíß Humidity: {humidity}%")
st.sidebar.text(f"üåßÔ∏è Rainfall: {rainfall}")

weather_alerts = get_weather_alerts()
st.sidebar.subheader("‚ö†Ô∏è Weather Alerts")
if weather_alerts:
    for alert in weather_alerts:
        st.sidebar.markdown(f"""
        **{alert['event']} ({alert['severity']})**
        üïí {alert['effective']} ‚Üí {alert['expires']}  
        üì¢ {alert['headline']}  
        üí¨ _{alert['desc'][:120]}..._
        """)
else:
    st.sidebar.info("No active weather alerts for Mumbai.")

# Optional manual override
temperature = st.sidebar.slider("Temperature (¬∞C) Override:", 22.0, 35.0, float(temperature), 0.5)
rainfall = st.sidebar.slider("Rainfall (mm) Override:", 0.0, 50.0, float(rainfall), 0.5)
humidity = st.sidebar.slider("Humidity (%) Override:", 50.0, 95.0, float(humidity), 1.0)

st.sidebar.subheader("üö¶ Environment")
traffic_density = st.sidebar.selectbox("Traffic Density:", ['low', 'medium', 'high'], index=1)
event_nearby = st.sidebar.checkbox("Special Event Nearby", value=False)
competitor_count = st.sidebar.slider("Nearby Competitors:", 0, 15, 6)

st.sidebar.subheader("üéâ Festival Options")
festival_options = ['None', 'Independence Day', 'Janmashtami', 'Dahi Handi', 
                   'Ganesh Chaturthi', 'Ganesh Visarjan', 'Eid-e-Milad']
selected_festival = st.sidebar.selectbox("Simulate Festival:", festival_options)

# ----------------------------
# Vendor details
vendor_details = {
    'vendor_01': {'location_type': 'business_district', 'cuisine_type': 'main_course', 'avg_price': 85.0, 'menu_diversity': 12, 'peak_hours': [12, 13, 19, 20]},
    'vendor_02': {'location_type': 'near_college', 'cuisine_type': 'chai_snacks', 'avg_price': 25.0, 'menu_diversity': 8, 'peak_hours': [7, 8, 16, 17, 18]},
    'vendor_03': {'location_type': 'market', 'cuisine_type': 'chaat', 'avg_price': 45.0, 'menu_diversity': 15, 'peak_hours': [17, 18, 19, 20, 21]},
    'vendor_04': {'location_type': 'metro_station', 'cuisine_type': 'beverages', 'avg_price': 35.0, 'menu_diversity': 10, 'peak_hours': [7, 8, 9, 17, 18, 19]},
    'vendor_05': {'location_type': 'office', 'cuisine_type': 'dessert', 'avg_price': 65.0, 'menu_diversity': 7, 'peak_hours': [15, 16, 21, 22]}
}

# ----------------------------
# Safe encoding
def safe_transform(encoder, value):
    return encoder.transform([value])[0] if value in encoder.classes_ else -1

# ----------------------------
# Feature generation
def create_prediction_features(vendor_id, date, hour, temp, rain, humid, traffic, 
                               event, competitors, festival):
    vendor_info = vendor_details[vendor_id]
    dt = pd.Timestamp(datetime.combine(date, datetime.min.time()) + timedelta(hours=hour)).tz_localize('Asia/Kolkata')
    day_of_week = dt.weekday()
    is_weekend = int(day_of_week >= 5)
    is_festival = int(festival != 'None')
    is_holiday = int(festival in ['Independence Day'])
    wind_speed = 15.0 + (5.0 if rain > 0 else 0.0)
    is_peak_hour = int(hour in vendor_info['peak_hours'])
    is_evening = int(17 <= hour <= 21)
    is_morning = int(6 <= hour <= 10)
    base_demand = 15 if vendor_id == 'vendor_01' else 20
    lag_1h = max(1, int(base_demand * (0.8 + 0.4 * np.random.random())))
    lag_24h = max(1, int(base_demand * (0.9 + 0.2 * np.random.random())))
    rolling_avg = (lag_1h + lag_24h) / 2

    features = {
        'vendor_id_encoded': safe_transform(label_encoders['vendor_id'], vendor_id),
        'location_type_encoded': safe_transform(label_encoders['location_type'], vendor_info['location_type']),
        'cuisine_type_encoded': safe_transform(label_encoders['cuisine_type'], vendor_info['cuisine_type']),
        'avg_price': vendor_info['avg_price'],
        'menu_diversity': vendor_info['menu_diversity'],
        'hour_of_day': hour,
        'day_of_week': day_of_week,
        'is_weekend': is_weekend,
        'is_holiday': is_holiday,
        'is_festival': is_festival,
        'temperature_c': temp,
        'rainfall_mm': rain,
        'humidity_pct': humid,
        'wind_speed_kmh': wind_speed,
        'event_nearby': int(event),
        'traffic_density_encoded': safe_transform(label_encoders['traffic_density'], traffic),
        'competitor_count': competitors,
        'lag_1h_units': lag_1h,
        'lag_24h_units': lag_24h,
        'rolling_avg_24h': rolling_avg,
        'is_peak_hour': is_peak_hour,
        'is_evening': is_evening,
        'is_morning': is_morning
    }
    return pd.DataFrame([features]), vendor_info

# ----------------------------
# Prediction explanation
def generate_explanation(prediction, features_df, vendor_info, festival):
    hour = features_df.iloc[0]['hour_of_day']
    is_peak = features_df.iloc[0]['is_peak_hour']
    rainfall = features_df.iloc[0]['rainfall_mm']
    traffic = features_df.iloc[0]['traffic_density_encoded']
    is_festival_day = features_df.iloc[0]['is_festival']

    explanation = f"**Predicted demand: {prediction:.0f} units**\n\n"
    explanation += "‚úÖ **Peak hour boost**\n" if is_peak else "‚ö†Ô∏è **Off-peak hour**\n"
    if rainfall > 5:
        explanation += "‚òî **Rain effect**\n"
    if is_festival_day:
        explanation += "üéâ **Festival effect**\n"
    traffic_names = {0: 'Low', 1: 'Medium', 2: 'High'}
    traffic_name = traffic_names.get(int(traffic), 'Medium')
    if traffic == 2:
        explanation += "üöó **High traffic boost**\n"
    elif traffic == 0:
        explanation += "üö∂ **Low traffic reduction**\n"

    location_insights = {
        'business_district': 'Office workers drive weekday lunch/dinner demand',
        'market': 'Market location benefits from continuous foot traffic',
        'metro_station': 'Commuters create morning and evening rush patterns',
        'near_college': 'Students provide consistent demand with price sensitivity',
        'office': 'Corporate area with break-time and after-work peaks'
    }

    explanation += f"üìç **Location insight**: {location_insights[vendor_info['location_type']]}"
    return explanation

# ----------------------------
# Layout columns
col1, col2= st.columns([1,1])

with col1:
    st.subheader("üéØ Demand Prediction")
    if st.button("üîÆ Predict Units", type="primary"):
        features_df, vendor_info = create_prediction_features(
            selected_vendor, selected_date, selected_hour,
            temperature, rainfall, humidity, traffic_density,
            event_nearby, competitor_count, selected_festival
        )
        prediction = model.predict(features_df)[0]
        uncertainty = float(metadata.get('prediction_uncertainty_std', 3.0))
        st.success(f"**Predicted Units Sold: {prediction:.0f}**")
        st.markdown("### üìù Prediction Explanation")
        st.markdown(generate_explanation(prediction, features_df, vendor_info, selected_festival))
        st.session_state.last_prediction = prediction
        st.session_state.last_features = features_df
        st.session_state.last_vendor = selected_vendor

with col2:
    st.subheader("üõ†Ô∏è Scenario Parameters")
    st.markdown(f"""
    - **Vendor:** {vendor_options[selected_vendor]}
    - **Date/Time:** {selected_date} at {selected_hour}:00
    - **Temperature:** {temperature:.1f} ¬∞C
    - **Rainfall:** {rainfall:.1f} mm
    - **Humidity:** {humidity:.1f} %
    - **Traffic Density:** {traffic_density.capitalize()}
    - **Special Event Nearby:** {"Yes" if event_nearby else "No"}
    - **Nearby Competitors:** {competitor_count}
    - **Simulated Festival:** {selected_festival if selected_festival != 'None' else 'No Festival'}
    """)

# ----------------------------
# Historical & chart visualization
# Keep your existing charts unchanged
st.subheader("üìà Historical Context")
if historical_data is not None:
        vendor_hist = historical_data[historical_data['vendor_id'] == selected_vendor].copy()
        if not vendor_hist.empty:
            tab1, tab2 = st.tabs([ "üïí Hourly Pattern","üìÖ 48-Hour Context"])
            with tab1:
                hourly_avg = vendor_hist.groupby('hour_of_day')['units_sold'].agg(['mean','std']).reset_index()
                fig = go.Figure()
                fig.add_trace(go.Scatter(x=hourly_avg['hour_of_day'], y=hourly_avg['mean'], mode='lines+markers', line=dict(color='green', width=3)))
                fig.add_trace(go.Scatter(x=hourly_avg['hour_of_day'], y=hourly_avg['mean']+hourly_avg['std'], mode='lines', line=dict(width=0), showlegend=False))
                fig.add_trace(go.Scatter(x=hourly_avg['hour_of_day'], y=hourly_avg['mean']-hourly_avg['std'], mode='lines', line=dict(width=0), fill='tonexty', fillcolor='rgba(0,200,100,0.2)', showlegend=False))
                fig.add_vline(x=selected_hour, line_dash="dash", line_color="red", annotation_text=f"Selected: {selected_hour}:00")
                fig.update_layout(title="Average Hourly Demand Pattern", xaxis_title="Hour", yaxis_title="Avg Units Sold", height=400)
                st.plotly_chart(fig, use_container_width=True)
            with tab2:
                target_dt = pd.Timestamp(datetime.combine(selected_date, datetime.min.time()) + timedelta(hours=selected_hour)).tz_localize('Asia/Kolkata')
                start_dt = target_dt - timedelta(hours=24)
                end_dt = target_dt + timedelta(hours=24)
                context_data = vendor_hist[
                    (vendor_hist['datetime_parsed'] >= start_dt) &
                    (vendor_hist['datetime_parsed'] <= end_dt)
                ].copy()
                if not context_data.empty:
                    fig1 = go.Figure()
                    fig1.add_trace(go.Scatter(
                        x=context_data['datetime_parsed'].dt.tz_convert(None),
                        y=context_data['units_sold'],
                        mode='lines+markers',
                        line=dict(color='blue', width=2)
                    ))
                    fig1.update_layout(title="48-Hour Demand Context", xaxis_title="Date/Time", yaxis_title="Units Sold", height=400)
                    st.plotly_chart(fig1, use_container_width=True)
st.subheader("üìÜ Daily Average Demand")
daily_avg = vendor_hist.groupby(vendor_hist['datetime_parsed'].dt.date)['units_sold'].mean().reset_index()
fig_daily = go.Figure()
fig_daily.add_trace(go.Bar(
    x=daily_avg['datetime_parsed'], 
    y=daily_avg['units_sold'], 
    marker_color='orange'
))
fig_daily.update_layout(
    title="Average Daily Units Sold",
    xaxis_title="Date",
    yaxis_title="Avg Units Sold",
    height=400
)
st.plotly_chart(fig_daily, use_container_width=True)


st.subheader("üìä Average Demand by Weekday")
vendor_hist['weekday'] = vendor_hist['datetime_parsed'].dt.day_name()
weekday_avg = vendor_hist.groupby('weekday')['units_sold'].mean().reindex(
    ['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday']
).reset_index()
fig_weekday = go.Figure()
fig_weekday.add_trace(go.Bar(
    x=weekday_avg['weekday'],
    y=weekday_avg['units_sold'],
    marker_color='green'
))
fig_weekday.update_layout(
    title="Average Units Sold by Weekday",
    xaxis_title="Weekday",
    yaxis_title="Avg Units Sold",
    height=400
)
st.plotly_chart(fig_weekday, use_container_width=True)


st.subheader("üå°Ô∏è Temperature vs Demand")
fig_temp = go.Figure()
fig_temp.add_trace(go.Scatter(
    x=vendor_hist['temperature_c'],
    y=vendor_hist['units_sold'],
    mode='markers',
    marker=dict(size=8, color='red', opacity=0.6)
))
fig_temp.update_layout(
    title="Temperature vs Units Sold",
    xaxis_title="Temperature (¬∞C)",
    yaxis_title="Units Sold",
    height=400
)
st.plotly_chart(fig_temp, use_container_width=True)


st.subheader("‚òî Rainfall Impact on Demand")
fig_rain = go.Figure()
fig_rain.add_trace(go.Box(
    x=vendor_hist['rainfall_mm'].round(0),
    y=vendor_hist['units_sold'],
    marker_color='blue'
))
fig_rain.update_layout(
    title="Units Sold vs Rainfall",
    xaxis_title="Rainfall (mm)",
    yaxis_title="Units Sold",
    height=400
)
st.plotly_chart(fig_rain, use_container_width=True)


st.subheader("üî• Hourly Demand Heatmap by Weekday")
heatmap_data = vendor_hist.groupby(['weekday','hour_of_day'])['units_sold'].mean().reset_index()
heatmap_data['weekday'] = pd.Categorical(heatmap_data['weekday'], 
                                         categories=['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday'], 
                                         ordered=True)
heatmap_pivot = heatmap_data.pivot(index='hour_of_day', columns='weekday', values='units_sold')
fig_heat = go.Figure(data=go.Heatmap(
    z=heatmap_pivot.values,
    x=heatmap_pivot.columns,
    y=heatmap_pivot.index,
    colorscale='Viridis'
))
fig_heat.update_layout(
    title="Heatmap of Average Units Sold by Hour and Weekday",
    xaxis_title="Weekday",
    yaxis_title="Hour of Day",
    height=500
)
st.plotly_chart(fig_heat, use_container_width=True)



st.subheader("üå¶Ô∏è Temperature, Rainfall & Demand (3D)")
fig_3d = go.Figure()
fig_3d.add_trace(go.Scatter3d(
    x=vendor_hist['temperature_c'],
    y=vendor_hist['rainfall_mm'],
    z=vendor_hist['units_sold'],
    mode='markers',
    marker=dict(size=5, color=vendor_hist['units_sold'], colorscale='Rainbow', opacity=0.8)
))
fig_3d.update_layout(
    scene=dict(
        xaxis_title='Temperature (¬∞C)',
        yaxis_title='Rainfall (mm)',
        zaxis_title='Units Sold'
    ),
    height=600,
    title="3D Scatter: Temperature & Rainfall vs Demand"
)
st.plotly_chart(fig_3d, use_container_width=True)


# ----------------------------
# üìä Additional Visualizations
st.markdown("---")
st.header("üß† Advanced Insights & Comparisons")

# 1Ô∏è‚É£ Feature Correlation Heatmap
st.subheader("üìä Feature Correlation Heatmap (Numeric Variables)")
try:
    numeric_cols = ['units_sold', 'temperature_c', 'rainfall_mm', 'humidity_pct', 'avg_price', 'competitor_count']
    corr_data = vendor_hist[numeric_cols].corr()
    fig_corr = go.Figure(data=go.Heatmap(
        z=corr_data.values,
        x=corr_data.columns,
        y=corr_data.columns,
        colorscale="RdBu",
        zmid=0
    ))
    fig_corr.update_layout(
        title="Correlation Matrix Between Key Variables",
        height=500
    )
    st.plotly_chart(fig_corr, use_container_width=True)
except Exception as e:
    st.warning(f"Could not plot correlation heatmap: {e}")

# 2Ô∏è‚É£ 7-Day Rolling Average Trend
st.subheader("üìà 7-Day Rolling Average Demand Trend")
try:
    daily_avg['rolling_7d'] = daily_avg['units_sold'].rolling(7, min_periods=1).mean()
    fig_trend = go.Figure()
    fig_trend.add_trace(go.Scatter(
        x=daily_avg['datetime_parsed'],
        y=daily_avg['rolling_7d'],
        mode='lines+markers',
        line=dict(color='purple', width=3)
    ))
    fig_trend.update_layout(
        title="7-Day Smoothed Demand Trend",
        xaxis_title="Date",
        yaxis_title="7-Day Rolling Avg Units Sold",
        height=400
    )
    st.plotly_chart(fig_trend, use_container_width=True)
except Exception as e:
    st.warning(f"Could not plot rolling trend: {e}")

# 3Ô∏è‚É£ Vendor Comparison Chart
st.subheader("üè™ Vendor Comparison (Avg Daily Sales)")
try:
    vendor_comparison = historical_data.groupby('vendor_id')['units_sold'].mean().reset_index()
    vendor_comparison['vendor_name'] = vendor_comparison['vendor_id'].map(vendor_options)
    fig_comp = go.Figure()
    fig_comp.add_trace(go.Bar(
        x=vendor_comparison['vendor_name'],
        y=vendor_comparison['units_sold'],
        marker_color='teal'
    ))
    fig_comp.update_layout(
        title="Average Daily Sales Comparison Across Vendors",
        xaxis_title="Vendor",
        yaxis_title="Average Units Sold",
        height=400
    )
    st.plotly_chart(fig_comp, use_container_width=True)
except Exception as e:
    st.warning(f"Could not plot vendor comparison: {e}")

# ----------------------------
# üì• Download Prediction Option
st.markdown("---")
st.header("üì• Export Prediction Result")

if 'last_prediction' in st.session_state and 'last_features' in st.session_state:
    result_df = st.session_state.last_features.copy()
    result_df['predicted_units'] = st.session_state.last_prediction
    result_df['vendor_name'] = vendor_options[st.session_state.last_vendor]
    result_df['prediction_time'] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    csv_data = result_df.to_csv(index=False).encode('utf-8')
    st.download_button(
        label="‚¨áÔ∏è Download Latest Prediction as CSV",
        data=csv_data,
        file_name=f"{st.session_state.last_vendor}_prediction.csv",
        mime="text/csv",
    )
else:
    st.info("Run a prediction first to enable download.")




# app_complete.py
import streamlit as st
import pandas as pd
import numpy as np
import joblib
import json
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

# ----------------------------
# Page config
st.set_page_config(
    page_title="Mumbai Street Vendor Demand Forecasting",
    page_icon="üçõ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ----------------------------
# ----------------------------
# Translation dictionary
translations = {
    "English": {
        "app_title": "Mumbai Street Vendor Demand Forecasting",
        "app_subtitle": "Predict hourly demand and explore scenario simulations with interactive charts.",
        "select_language": "Select Language",
        "predict_units": "Predict Units",
        "temperature": "Temperature",
        "rainfall": "Rainfall",
        "humidity": "Humidity",
        "weather_alerts": "Weather Alerts",
        "no_alerts": "No active weather alerts for Mumbai.",
        "vendor_select": "Select Vendor:",
        "date": "Select Date:",
        "hour": "Select Hour:",
        "temperature_override": "Temperature (¬∞C) Override:",
        "rainfall_override": "Rainfall (mm) Override:",
        "humidity_override": "Humidity (%) Override:",
        "traffic_density": "Traffic Density:",
        "special_event": "Special Event Nearby",
        "nearby_competitors": "Nearby Competitors:",
        "simulate_festival": "Simulate Festival:",
        "demand_prediction": "Demand Prediction",
        "scenario_parameters": "Scenario Parameters",
        "historical_context": "Historical Context",
        "daily_avg_demand": "Daily Average Demand",
        "avg_demand_weekday": "Average Demand by Weekday",
        "temp_vs_demand": "Temperature vs Demand",
        "rainfall_vs_demand": "Rainfall Impact on Demand",
        "hourly_heatmap": "Hourly Demand Heatmap by Weekday",
        "temp_rain_demand_3d": "Temperature, Rainfall & Demand (3D)",
        "feature_corr_heatmap": "Feature Correlation Heatmap (Numeric Variables)",
        "rolling_trend": "7-Day Rolling Average Demand Trend",
        "vendor_comparison": "Vendor Comparison (Avg Daily Sales)",
        "export_prediction": "Export Prediction Result",
        "run_prediction_first": "Run a prediction first to enable download.",
        "prediction_success": "Predicted Units Sold:",
        "prediction_explanation": "Prediction Explanation",
        "prediction_controls": "Prediction Controls",
        "weather_section": "Weather Conditions (Auto-Filled)",
        "environment": "Environment",
        "events": "Events",
        "footer": "Mumbai Street Vendor Demand Forecasting System | Streamlit & ML-powered predictions"
    },
    "Hindi": {
        "app_title": "‡§Æ‡•Å‡§Ç‡§¨‡§à ‡§∏‡•ç‡§ü‡•ç‡§∞‡•Ä‡§ü ‡§µ‡§ø‡§ï‡•ç‡§∞‡•á‡§§‡§æ ‡§Æ‡§æ‡§Ç‡§ó ‡§™‡•Ç‡§∞‡•ç‡§µ‡§æ‡§®‡•Å‡§Æ‡§æ‡§®",
        "app_subtitle": "‡§ò‡§Ç‡§ü‡§æ-‡§ò‡§Ç‡§ü‡§æ ‡§Æ‡§æ‡§Ç‡§ó ‡§ï‡§æ ‡§™‡•Ç‡§∞‡•ç‡§µ‡§æ‡§®‡•Å‡§Æ‡§æ‡§® ‡§≤‡§ó‡§æ‡§è‡§Å ‡§î‡§∞ ‡§á‡§Ç‡§ü‡§∞‡•à‡§ï‡•ç‡§ü‡§ø‡§µ ‡§ö‡§æ‡§∞‡•ç‡§ü‡•ç‡§∏ ‡§ï‡•á ‡§∏‡§æ‡§• ‡§™‡§∞‡§ø‡§¶‡•É‡§∂‡•ç‡§Ø ‡§∏‡§ø‡§Æ‡•Å‡§≤‡•á‡§∂‡§® ‡§¶‡•á‡§ñ‡•á‡§Ç‡•§",
        "select_language": "‡§≠‡§æ‡§∑‡§æ ‡§ö‡•Å‡§®‡•á‡§Ç",
        "predict_units": "‡§Ø‡•Ç‡§®‡§ø‡§ü‡•ç‡§∏ ‡§ï‡§æ ‡§™‡•Ç‡§∞‡•ç‡§µ‡§æ‡§®‡•Å‡§Æ‡§æ‡§® ‡§≤‡§ó‡§æ‡§è‡§Å",
        "temperature": "‡§§‡§æ‡§™‡§Æ‡§æ‡§®",
        "rainfall": "‡§µ‡§∞‡•ç‡§∑‡§æ",
        "humidity": "‡§Ü‡§∞‡•ç‡§¶‡•ç‡§∞‡§§‡§æ",
        "weather_alerts": "‡§Æ‡•å‡§∏‡§Æ ‡§Ö‡§≤‡§∞‡•ç‡§ü",
        "no_alerts": "‡§Æ‡•Å‡§Ç‡§¨‡§à ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ï‡•ã‡§à ‡§∏‡§ï‡•ç‡§∞‡§ø‡§Ø ‡§Æ‡•å‡§∏‡§Æ ‡§Ö‡§≤‡§∞‡•ç‡§ü ‡§®‡§π‡•Ä‡§Ç‡•§",
        "vendor_select": "‡§µ‡§ø‡§ï‡•ç‡§∞‡•á‡§§‡§æ ‡§ö‡•Å‡§®‡•á‡§Ç:",
        "date": "‡§§‡§æ‡§∞‡•Ä‡§ñ ‡§ö‡•Å‡§®‡•á‡§Ç:",
        "hour": "‡§ò‡§Ç‡§ü‡§æ ‡§ö‡•Å‡§®‡•á‡§Ç:",
        "temperature_override": "‡§§‡§æ‡§™‡§Æ‡§æ‡§® (¬∞C) ‡§ì‡§µ‡§∞‡§∞‡§æ‡§á‡§°:",
        "rainfall_override": "‡§µ‡§∞‡•ç‡§∑‡§æ (mm) ‡§ì‡§µ‡§∞‡§∞‡§æ‡§á‡§°:",
        "humidity_override": "‡§Ü‡§∞‡•ç‡§¶‡•ç‡§∞‡§§‡§æ (%) ‡§ì‡§µ‡§∞‡§∞‡§æ‡§á‡§°:",
        "traffic_density": "‡§ü‡•ç‡§∞‡•à‡§´‡§ø‡§ï ‡§ò‡§®‡§§‡•ç‡§µ:",
        "special_event": "‡§™‡§æ‡§∏ ‡§Æ‡•á‡§Ç ‡§µ‡§ø‡§∂‡•á‡§∑ ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§ï‡•ç‡§∞‡§Æ",
        "nearby_competitors": "‡§™‡§æ‡§∏ ‡§ï‡•á ‡§™‡•ç‡§∞‡§§‡§ø‡§Ø‡•ã‡§ó‡•Ä:",
        "simulate_festival": "‡§§‡•ç‡§Ø‡•ã‡§π‡§æ‡§∞ ‡§∏‡§ø‡§Æ‡•Å‡§≤‡•á‡§ü ‡§ï‡§∞‡•á‡§Ç:",
        "demand_prediction": "‡§Æ‡§æ‡§Ç‡§ó ‡§™‡•Ç‡§∞‡•ç‡§µ‡§æ‡§®‡•Å‡§Æ‡§æ‡§®",
        "scenario_parameters": "‡§™‡§∞‡§ø‡§¶‡•É‡§∂‡•ç‡§Ø ‡§™‡•à‡§∞‡§æ‡§Æ‡•Ä‡§ü‡§∞",
        "historical_context": "‡§ê‡§§‡§ø‡§π‡§æ‡§∏‡§ø‡§ï ‡§∏‡§Ç‡§¶‡§∞‡•ç‡§≠",
        "daily_avg_demand": "‡§¶‡•à‡§®‡§ø‡§ï ‡§î‡§∏‡§§ ‡§Æ‡§æ‡§Ç‡§ó",
        "avg_demand_weekday": "‡§∏‡§™‡•ç‡§§‡§æ‡§π ‡§ï‡•á ‡§¶‡§ø‡§® ‡§ï‡•á ‡§Ö‡§®‡•Å‡§∏‡§æ‡§∞ ‡§î‡§∏‡§§ ‡§Æ‡§æ‡§Ç‡§ó",
        "temp_vs_demand": "‡§§‡§æ‡§™‡§Æ‡§æ‡§® ‡§¨‡§®‡§æ‡§Æ ‡§Æ‡§æ‡§Ç‡§ó",
        "rainfall_vs_demand": "‡§µ‡§∞‡•ç‡§∑‡§æ ‡§ï‡§æ ‡§™‡•ç‡§∞‡§≠‡§æ‡§µ",
        "hourly_heatmap": "‡§∏‡§™‡•ç‡§§‡§æ‡§π ‡§ï‡•á ‡§¶‡§ø‡§® ‡§î‡§∞ ‡§ò‡§Ç‡§ü‡•á ‡§ï‡•á ‡§Ö‡§®‡•Å‡§∏‡§æ‡§∞ ‡§Æ‡§æ‡§Ç‡§ó ‡§π‡•Ä‡§ü‡§Æ‡•à‡§™",
        "temp_rain_demand_3d": "‡§§‡§æ‡§™‡§Æ‡§æ‡§®, ‡§µ‡§∞‡•ç‡§∑‡§æ ‡§î‡§∞ ‡§Æ‡§æ‡§Ç‡§ó (3D)",
        "feature_corr_heatmap": "‡§Æ‡•Å‡§ñ‡•ç‡§Ø ‡§µ‡§ø‡§∂‡•á‡§∑‡§§‡§æ‡§ì‡§Ç ‡§ï‡§æ ‡§∏‡§π‡§∏‡§Ç‡§¨‡§Ç‡§ß ‡§π‡•Ä‡§ü‡§Æ‡•à‡§™",
        "rolling_trend": "7-‡§¶‡§ø‡§® ‡§ï‡•Ä ‡§î‡§∏‡§§ ‡§Æ‡§æ‡§Ç‡§ó ‡§∞‡•Å‡§ù‡§æ‡§®",
        "vendor_comparison": "‡§µ‡§ø‡§ï‡•ç‡§∞‡•á‡§§‡§æ ‡§§‡•Å‡§≤‡§®‡§æ (‡§î‡§∏‡§§ ‡§¶‡•à‡§®‡§ø‡§ï ‡§¨‡§ø‡§ï‡•ç‡§∞‡•Ä)",
        "export_prediction": "‡§™‡•Ç‡§∞‡•ç‡§µ‡§æ‡§®‡•Å‡§Æ‡§æ‡§® ‡§™‡§∞‡§ø‡§£‡§æ‡§Æ ‡§®‡§ø‡§∞‡•ç‡§Ø‡§æ‡§§ ‡§ï‡§∞‡•á‡§Ç",
        "run_prediction_first": "‡§°‡§æ‡§â‡§®‡§≤‡•ã‡§° ‡§∏‡§ï‡•ç‡§∑‡§Æ ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§™‡§π‡§≤‡•á ‡§™‡•Ç‡§∞‡•ç‡§µ‡§æ‡§®‡•Å‡§Æ‡§æ‡§® ‡§ö‡§≤‡§æ‡§è‡§Å‡•§",
        "prediction_success": "‡§™‡•Ç‡§∞‡•ç‡§µ‡§æ‡§®‡•Å‡§Æ‡§æ‡§®‡§ø‡§§ ‡§Ø‡•Ç‡§®‡§ø‡§ü‡•ç‡§∏:",
        "prediction_explanation": "‡§™‡•Ç‡§∞‡•ç‡§µ‡§æ‡§®‡•Å‡§Æ‡§æ‡§® ‡§µ‡•ç‡§Ø‡§æ‡§ñ‡•ç‡§Ø‡§æ",
        "prediction_controls": "‡§™‡•Ç‡§∞‡•ç‡§µ‡§æ‡§®‡•Å‡§Æ‡§æ‡§® ‡§®‡§ø‡§Ø‡§Ç‡§§‡•ç‡§∞‡§£",
        "weather_section": "‡§Æ‡•å‡§∏‡§Æ ‡§∏‡•ç‡§•‡§ø‡§§‡§ø‡§Ø‡§æ‡§Å (‡§ë‡§ü‡•ã-‡§≠‡§∞‡•Ä ‡§π‡•Å‡§à)",
        "environment": "‡§™‡§∞‡•ç‡§Ø‡§æ‡§µ‡§∞‡§£",
        "events": "‡§á‡§µ‡•á‡§Ç‡§ü‡•ç‡§∏",
        "footer": "‡§Æ‡•Å‡§Ç‡§¨‡§à ‡§∏‡•ç‡§ü‡•ç‡§∞‡•Ä‡§ü ‡§µ‡§ø‡§ï‡•ç‡§∞‡•á‡§§‡§æ ‡§Æ‡§æ‡§Ç‡§ó ‡§™‡•Ç‡§∞‡•ç‡§µ‡§æ‡§®‡•Å‡§Æ‡§æ‡§® ‡§∏‡§ø‡§∏‡•ç‡§ü‡§Æ | Streamlit & ML ‡§¶‡•ç‡§µ‡§æ‡§∞‡§æ ‡§∏‡§Ç‡§ö‡§æ‡§≤‡§ø‡§§"
    },
    "Marathi": {
        "app_title": "‡§Æ‡•Å‡§Ç‡§¨‡§à ‡§∏‡•ç‡§ü‡•ç‡§∞‡•Ä‡§ü ‡§µ‡§ø‡§ï‡•ç‡§∞‡•á‡§§‡§æ ‡§Æ‡§æ‡§ó‡§£‡•Ä ‡§Ö‡§Ç‡§¶‡§æ‡§ú",
        "app_subtitle": "‡§§‡§æ‡§∏‡§æ‡§Ç‡§®‡•Å‡§∏‡§æ‡§∞ ‡§Æ‡§æ‡§ó‡§£‡•Ä‡§ö‡•á ‡§Ö‡§Ç‡§¶‡§æ‡§ú ‡§≤‡§æ‡§µ‡§æ ‡§Ü‡§£‡§ø ‡§á‡§Ç‡§ü‡§∞‡•Ö‡§ï‡•ç‡§ü‡§ø‡§µ ‡§ö‡§æ‡§∞‡•ç‡§ü‡§∏‡§π ‡§∏‡§ø‡§Æ‡•ç‡§Ø‡•Å‡§≤‡•á‡§∂‡§® ‡§™‡§π‡§æ.",
        "select_language": "‡§≠‡§æ‡§∑‡§æ ‡§®‡§ø‡§µ‡§°‡§æ",
        "predict_units": "‡§Ø‡•Å‡§®‡§ø‡§ü‡•ç‡§∏‡§ö‡§æ ‡§Ö‡§Ç‡§¶‡§æ‡§ú ‡§≤‡§æ‡§µ‡§æ",
        "temperature": "‡§§‡§æ‡§™‡§Æ‡§æ‡§®",
        "rainfall": "‡§™‡§æ‡§ä‡§∏",
        "humidity": "‡§Ü‡§∞‡•ç‡§¶‡•ç‡§∞‡§§‡§æ",
        "weather_alerts": "‡§π‡§µ‡§æ‡§Æ‡§æ‡§® ‡§Ö‡§≤‡§∞‡•ç‡§ü",
        "no_alerts": "‡§Æ‡•Å‡§Ç‡§¨‡§à‡§∏‡§æ‡§†‡•Ä ‡§ï‡•ã‡§£‡§§‡§æ‡§π‡•Ä ‡§∏‡§ï‡•ç‡§∞‡§ø‡§Ø ‡§π‡§µ‡§æ‡§Æ‡§æ‡§® ‡§Ö‡§≤‡§∞‡•ç‡§ü ‡§®‡§æ‡§π‡•Ä.",
        "vendor_select": "‡§µ‡§ø‡§ï‡•ç‡§∞‡•á‡§§‡§æ ‡§®‡§ø‡§µ‡§°‡§æ:",
        "date": "‡§§‡§æ‡§∞‡•Ä‡§ñ ‡§®‡§ø‡§µ‡§°‡§æ:",
        "hour": "‡§§‡§æ‡§∏ ‡§®‡§ø‡§µ‡§°‡§æ:",
        "temperature_override": "‡§§‡§æ‡§™‡§Æ‡§æ‡§® (¬∞C) ‡§ì‡§µ‡•ç‡§π‡§∞‡§∞‡§æ‡§à‡§°:",
        "rainfall_override": "‡§™‡§æ‡§ä‡§∏ (mm) ‡§ì‡§µ‡•ç‡§π‡§∞‡§∞‡§æ‡§à‡§°:",
        "humidity_override": "‡§Ü‡§∞‡•ç‡§¶‡•ç‡§∞‡§§‡§æ (%) ‡§ì‡§µ‡•ç‡§π‡§∞‡§∞‡§æ‡§à‡§°:",
        "traffic_density": "‡§µ‡§æ‡§π‡§® ‡§¶‡§æ‡§ü‡•Ä:",
        "special_event": "‡§∂‡•á‡§ú‡§æ‡§∞‡•Ä‡§≤ ‡§µ‡§ø‡§∂‡•á‡§∑ ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§ï‡•ç‡§∞‡§Æ",
        "nearby_competitors": "‡§∂‡•á‡§ú‡§æ‡§∞‡•Ä‡§≤ ‡§∏‡•ç‡§™‡§∞‡•ç‡§ß‡§ï:",
        "simulate_festival": "‡§∏‡§£ ‡§∏‡§ø‡§Æ‡•ç‡§Ø‡•Å‡§≤‡•á‡§ü ‡§ï‡§∞‡§æ:",
        "demand_prediction": "‡§Æ‡§æ‡§ó‡§£‡•Ä ‡§Ö‡§Ç‡§¶‡§æ‡§ú",
        "scenario_parameters": "‡§™‡§∞‡§ø‡§∏‡•ç‡§•‡§ø‡§§‡•Ä ‡§™‡•Ö‡§∞‡§æ‡§Æ‡•Ä‡§ü‡§∞‡•ç‡§∏",
        "historical_context": "‡§ê‡§§‡§ø‡§π‡§æ‡§∏‡§ø‡§ï ‡§∏‡§Ç‡§¶‡§∞‡•ç‡§≠",
        "daily_avg_demand": "‡§¶‡§∞‡§∞‡•ã‡§ú‡§ö‡•Ä ‡§∏‡§∞‡§æ‡§∏‡§∞‡•Ä ‡§Æ‡§æ‡§ó‡§£‡•Ä",
        "avg_demand_weekday": "‡§∏‡§™‡•ç‡§§‡§æ‡§π‡§æ‡§ö‡•ç‡§Ø‡§æ ‡§¶‡§ø‡§µ‡§∂‡•Ä ‡§∏‡§∞‡§æ‡§∏‡§∞‡•Ä ‡§Æ‡§æ‡§ó‡§£‡•Ä",
        "temp_vs_demand": "‡§§‡§æ‡§™‡§Æ‡§æ‡§® ‡§µ‡§ø‡§∞‡•Å‡§¶‡•ç‡§ß ‡§Æ‡§æ‡§ó‡§£‡•Ä",
        "rainfall_vs_demand": "‡§™‡§æ‡§µ‡§∏‡§æ‡§ö‡§æ ‡§™‡§∞‡§ø‡§£‡§æ‡§Æ",
        "hourly_heatmap": "‡§∏‡§™‡•ç‡§§‡§æ‡§π‡§æ‡§ö‡•ç‡§Ø‡§æ ‡§¶‡§ø‡§µ‡§∏‡§æ‡§Ç‡§®‡•Å‡§∏‡§æ‡§∞ ‡§§‡§æ‡§∏‡§æ‡§®‡•Å‡§∏‡§æ‡§∞ ‡§Æ‡§æ‡§ó‡§£‡•Ä ‡§π‡•Ä‡§ü‡§Æ‡•Ö‡§™",
        "temp_rain_demand_3d": "‡§§‡§æ‡§™‡§Æ‡§æ‡§®, ‡§™‡§æ‡§ä‡§∏ ‡§Ü‡§£‡§ø ‡§Æ‡§æ‡§ó‡§£‡•Ä (3D)",
        "feature_corr_heatmap": "‡§Æ‡•Å‡§ñ‡•ç‡§Ø ‡§µ‡•à‡§∂‡§ø‡§∑‡•ç‡§ü‡•ç‡§Ø‡•á ‡§∏‡§π‡§∏‡§Ç‡§¨‡§Ç‡§ß ‡§π‡•Ä‡§ü‡§Æ‡•à‡§™",
        "rolling_trend": "7-‡§¶‡§ø‡§µ‡§∏‡§æ‡§Ç‡§ö‡•Ä ‡§∏‡§∞‡§æ‡§∏‡§∞‡•Ä ‡§Æ‡§æ‡§ó‡§£‡•Ä ‡§™‡•ç‡§∞‡§µ‡§æ‡§π",
        "vendor_comparison": "‡§µ‡§ø‡§ï‡•ç‡§∞‡•á‡§§‡§æ ‡§§‡•Å‡§≤‡§®‡§æ (‡§∏‡§∞‡§æ‡§∏‡§∞‡•Ä ‡§¶‡•à‡§®‡§ø‡§ï ‡§µ‡§ø‡§ï‡•ç‡§∞‡•Ä)",
        "export_prediction": "‡§Ö‡§Ç‡§¶‡§æ‡§ú ‡§™‡§∞‡§ø‡§£‡§æ‡§Æ ‡§®‡§ø‡§∞‡•ç‡§Ø‡§æ‡§§ ‡§ï‡§∞‡§æ",
        "run_prediction_first": "‡§°‡§æ‡§â‡§®‡§≤‡•ã‡§° ‡§∏‡§ï‡•ç‡§∑‡§Æ ‡§ï‡§∞‡§£‡•ç‡§Ø‡§æ‡§∏‡§æ‡§†‡•Ä ‡§™‡•ç‡§∞‡§•‡§Æ ‡§Ö‡§Ç‡§¶‡§æ‡§ú ‡§ö‡§æ‡§≤‡§µ‡§æ.",
        "prediction_success": "‡§Ö‡§Ç‡§¶‡§æ‡§ú‡§ø‡§§ ‡§Ø‡•Å‡§®‡§ø‡§ü‡•ç‡§∏:",
        "prediction_explanation": "‡§Ö‡§Ç‡§¶‡§æ‡§ú ‡§∏‡•ç‡§™‡§∑‡•ç‡§ü‡•Ä‡§ï‡§∞‡§£",
        "prediction_controls": "‡§Ö‡§Ç‡§¶‡§æ‡§ú ‡§®‡§ø‡§Ø‡§Ç‡§§‡•ç‡§∞‡§£",
        "weather_section": "‡§π‡§µ‡§æ‡§Æ‡§æ‡§® ‡§∏‡•ç‡§•‡§ø‡§§‡•Ä (‡§ë‡§ü‡•ã-‡§≠‡§∞‡§≤‡•á‡§≤‡•á)",
        "environment": "‡§™‡§∞‡•ç‡§Ø‡§æ‡§µ‡§∞‡§£",
        "events": "‡§ï‡§æ‡§∞‡•ç‡§Ø‡§ï‡•ç‡§∞‡§Æ",
        "footer": "‡§Æ‡•Å‡§Ç‡§¨‡§à ‡§∏‡•ç‡§ü‡•ç‡§∞‡•Ä‡§ü ‡§µ‡§ø‡§ï‡•ç‡§∞‡•á‡§§‡§æ ‡§Æ‡§æ‡§ó‡§£‡•Ä ‡§Ö‡§Ç‡§¶‡§æ‡§ú ‡§™‡•ç‡§∞‡§£‡§æ‡§≤‡•Ä | Streamlit & ML-‡§∂‡§ï‡•ç‡§§‡•Ä‡§®‡•á"
    }
}

st.sidebar.subheader("Select Language")
language = st.sidebar.selectbox("", ["English", "Hindi", "Marathi"], index=0)
lang = translations[language]
def t(key): return lang.get(key, key)

# ----------------------------
# Load model & metadata
@st.cache_resource
def load_model_artifacts():
    model = joblib.load('rf_model.pkl')
    label_encoders = joblib.load('label_encoders.pkl')
    feature_columns = joblib.load('feature_columns.pkl')
    with open('model_metadata.json') as f:
        metadata = json.load(f)
    return model, label_encoders, feature_columns, metadata

model, label_encoders, feature_columns, metadata = load_model_artifacts()

# ----------------------------
# Load historical data
@st.cache_data
def load_historical_data():
    df = pd.read_csv('mumbai_vendors_hourly_20250701_20250930.csv')
    df['datetime_parsed'] = pd.to_datetime(df['datetime'], errors='coerce')
    if df['datetime_parsed'].dt.tz is None:
        df['datetime_parsed'] = df['datetime_parsed'].dt.tz_localize('Asia/Kolkata')
    else:
        df['datetime_parsed'] = df['datetime_parsed'].dt.tz_convert('Asia/Kolkata')
    return df

historical_data = load_historical_data()

# ----------------------------
# Feature preparation
def safe_transform(encoder, value):
    return encoder.transform([value])[0] if value in encoder.classes_ else -1

def create_prediction_features(vendor_id, date, hour, temp, rain, humid, traffic,
                               event, competitors, festival):
    vendor_info = {
        'vendor_01': {'location_type': 'business_district', 'cuisine_type': 'main_course', 'avg_price': 85.0, 'menu_diversity': 12, 'peak_hours': [12, 13, 19, 20]},
        'vendor_02': {'location_type': 'near_college', 'cuisine_type': 'chai_snacks', 'avg_price': 25.0, 'menu_diversity': 8, 'peak_hours': [7,8,16,17,18]},
        'vendor_03': {'location_type': 'market', 'cuisine_type': 'main_course', 'avg_price': 75.0, 'menu_diversity': 15, 'peak_hours': [11,12,19,20]}
    }
    info = vendor_info[vendor_id]
    df = pd.DataFrame({
        'vendor_id_encoded': [safe_transform(label_encoders['vendor_id'], vendor_id)],
        'location_type_encoded': [safe_transform(label_encoders['location_type'], info['location_type'])],
        'cuisine_type_encoded': [safe_transform(label_encoders['cuisine_type'], info['cuisine_type'])],
        'avg_price': [info['avg_price']],
        'menu_diversity': [info['menu_diversity']],
        'hour_of_day': [hour],
        'is_weekend': [1 if date.weekday()>=5 else 0],
        'is_holiday': [0],
        'is_festival': [festival],
        'temperature_c': [temp],
        'rainfall_mm': [rain],
        'humidity_pct': [humid],
        'wind_speed_kmh': [0],
        'event_nearby': [event],
        'traffic_density_encoded': [traffic],
        'competitor_count': [competitors],
        'lag_1h_units': [0],
        'lag_24h_units': [0],
        'rolling_avg_24h': [0],
        'is_peak_hour': [1 if hour in info['peak_hours'] else 0],
        'is_evening': [1 if 17<=hour<=20 else 0],
        'is_morning': [1 if 6<=hour<=11 else 0]
    })
    return df, info

# ----------------------------
# Sidebar controls
st.sidebar.subheader(t("prediction_controls"))
vendor_options = historical_data['vendor_id'].unique()
selected_vendor = st.sidebar.selectbox(t("vendor_select"), vendor_options)
selected_date = st.sidebar.date_input(t("date"), datetime.today())
selected_hour = st.sidebar.slider(t("hour"), 0, 23, datetime.now().hour)
temperature_override = st.sidebar.number_input(t("temperature_override"), value=30)
rainfall_override = st.sidebar.number_input(t("rainfall_override"), value=0)
humidity_override = st.sidebar.number_input(t("humidity_override"), value=70)
traffic_density = st.sidebar.slider(t("traffic_density"), 0, 10, 5)
special_event = st.sidebar.checkbox(t("special_event"))
nearby_competitors = st.sidebar.number_input(t("nearby_competitors"), value=0)
simulate_festival = st.sidebar.checkbox(t("simulate_festival"))

# ----------------------------
# Prediction
if st.sidebar.button(t("predict_units")):
    features_df, vendor_info = create_prediction_features(
        selected_vendor, selected_date, selected_hour,
        temperature_override, rainfall_override, humidity_override,
        traffic_density, special_event, nearby_competitors, simulate_festival
    )
    X = features_df[feature_columns]
    prediction = model.predict(X)[0]
    st.subheader(t("prediction_success"))
    st.write(prediction)

# ----------------------------
# Historical visualizations
st.subheader(t("historical_context"))

# Daily avg demand
daily_avg = historical_data.groupby(historical_data['datetime_parsed'].dt.date)['units_sold'].mean().reset_index()
fig_daily = px.line(daily_avg, x='datetime_parsed', y='units_sold', title=t("daily_avg_demand"))
st.plotly_chart(fig_daily, use_container_width=True)

# Hourly heatmap
historical_data['hour'] = historical_data['datetime_parsed'].dt.hour
historical_data['weekday'] = historical_data['datetime_parsed'].dt.day_name()
heatmap_data = historical_data.groupby(['weekday','hour'])['units_sold'].mean().reset_index()
heatmap_pivot = heatmap_data.pivot('weekday','hour','units_sold')
fig_heatmap = px.imshow(heatmap_pivot, aspect='auto', title=t("hourly_heatmap"))
st.plotly_chart(fig_heatmap, use_container_width=True)

# Temp vs Demand
fig_temp = px.scatter(historical_data, x='temperature_c', y='units_sold', color='vendor_id', trendline='ols', title=t("temp_vs_demand"))
st.plotly_chart(fig_temp, use_container_width=True)

# Rainfall vs Demand
fig_rain = px.scatter(historical_data, x='rainfall_mm', y='units_sold', color='vendor_id', trendline='ols', title=t("rainfall_vs_demand"))
st.plotly_chart(fig_rain, use_container_width=True)

# 3D plot: Temp, Rainfall, Demand
fig_3d = px.scatter_3d(historical_data, x='temperature_c', y='rainfall_mm', z='units_sold',
                       color='vendor_id', size='units_sold', title=t("temp_rain_demand_3d"))
st.plotly_chart(fig_3d, use_container_width=True)

# ----------------------------
# Footer
st.markdown("---")
st.markdown(t("footer"))
